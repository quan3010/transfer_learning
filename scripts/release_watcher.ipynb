{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d5e09b3-3f80-42d4-9656-a33b0d6ad446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data0/transfer_models/releases/v0.0-alpha3/educational-technology-collective-transfer_models-b96d2462899f339da82866c9c8f9603dbb44634b\n",
      "2022-03-07 12:55:15 INFO     src institution is um\n",
      "2022-03-07 12:55:15 DEBUG    reading data from ./data/preprocessed/um.feather\n",
      "2022-03-07 12:55:16 DEBUG    reading target data complete; preprocessing target data\n",
      "2022-03-07 12:55:16 DEBUG    processing column sex with 3 unique values\n",
      "2022-03-07 12:55:16 DEBUG    column sex_Other not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    processing column ethnicity with 8 unique values\n",
      "2022-03-07 12:55:16 DEBUG    processing column urm_status with 3 unique values\n",
      "2022-03-07 12:55:16 DEBUG    processing column cip2_major_1 with 25 unique values\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_01 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_02 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_06 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_07 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_08 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_10 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_12 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_17 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_18 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_19 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_20 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_21 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_22 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_25 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_28 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_29 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_32 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_33 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_34 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_35 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_36 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_37 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_39 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_41 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_43 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_46 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_47 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_48 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_49 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_53 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_55 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_56 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_57 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_58 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_59 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_60 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_1_61 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    processing column cip2_major_2 with 18 unique values\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_01 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_02 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_04 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_06 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_07 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_08 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_10 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_12 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_13 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_14 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_15 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_17 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_18 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_19 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_20 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_21 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_22 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_25 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_28 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_29 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_31 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_32 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_33 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_34 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_35 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_36 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_37 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_39 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_41 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_43 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_44 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_46 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_47 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_48 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_49 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_51 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_53 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_55 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_56 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_57 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_58 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_59 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_60 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    column cip2_major_2_61 not in data; creating dummy\n",
      "2022-03-07 12:55:16 DEBUG    preprocessing tgt data complete\n",
      "2022-03-07 12:55:16 DEBUG    splitting src data into train/test/validation\n",
      "2022-03-07 12:55:16 DEBUG    splitting complete\n",
      "2022-03-07 12:55:16 INFO     writing data description to ./metrics/um_train_descriptivestats_scaledFalse.csv\n",
      "2022-03-07 12:55:16 INFO     writing data description to ./metrics/um_test_descriptivestats_scaledFalse.csv\n",
      "2022-03-07 12:55:17 INFO     writing data description to ./metrics/um_validation_descriptivestats_scaledFalse.csv\n",
      "2022-03-07 12:55:17 INFO     writing data description to ./metrics/um_train_descriptivestats_scaledTrue.csv\n",
      "2022-03-07 12:55:18 INFO     writing data description to ./metrics/um_test_descriptivestats_scaledTrue.csv\n",
      "2022-03-07 12:55:18 INFO     writing data description to ./metrics/um_validation_descriptivestats_scaledTrue.csv\n",
      "2022-03-07 12:55:18 INFO     training model with uid interaction_degree1_model_typerandom_forest_src_institutionum\n",
      "2022-03-07 12:55:18 INFO     fitting model.\n",
      "2022-03-07 12:55:19 INFO     evaluating model.\n",
      "2022-03-07 12:55:19 INFO     printing validation metrics with source institution um on target institution um:\n",
      "                                             subgroup  ... n_test\n",
      "0     sexMale_urm_statusNon-Underrepresented Minority  ...   None\n",
      "1         sexMale_urm_statusUnderrepresented Minority  ...   None\n",
      "2                     sexMale_urm_statusInternational  ...   None\n",
      "3   sexFemale_urm_statusNon-Underrepresented Minority  ...   None\n",
      "4       sexFemale_urm_statusUnderrepresented Minority  ...   None\n",
      "5                   sexFemale_urm_statusInternational  ...   None\n",
      "6   sexNotIndicated_urm_statusNon-Underrepresented...  ...   None\n",
      "7   sexNotIndicated_urm_statusUnderrepresented Min...  ...   None\n",
      "8             sexNotIndicated_urm_statusInternational  ...   None\n",
      "9    sexOther_urm_statusNon-Underrepresented Minority  ...   None\n",
      "10       sexOther_urm_statusUnderrepresented Minority  ...   None\n",
      "11                   sexOther_urm_statusInternational  ...   None\n",
      "12                                            sexMale  ...   None\n",
      "13                                          sexFemale  ...   None\n",
      "14                                    sexNotIndicated  ...   None\n",
      "15                                           sexOther  ...   None\n",
      "16            urm_statusNon-Underrepresented Minority  ...   None\n",
      "17                urm_statusUnderrepresented Minority  ...   None\n",
      "18                            urm_statusInternational  ...   None\n",
      "19                                          full_test  ...   1431\n",
      "\n",
      "[20 rows x 5 columns]\n",
      "2022-03-07 12:55:19 INFO     saved model to ./models/interaction_degree1_model_typerandom_forest_src_institutionum.joblib\n",
      "2022-03-07 12:55:19 INFO     metrics saved to ./metrics/metrics_src_um.csv\n",
      "/data1/home/brooksch/sandboxes/transfer_models/scripts\n"
     ]
    }
   ],
   "source": [
    "# The directory that release tarballs will be downloaded to, will contain a config file of previous runs\n",
    "# This directory should have a trailing slash\n",
    "RELEASE_DIR='/data0/transfer_models/releases/'\n",
    "\n",
    "# The directory that includes all pre-processed data to be made available to the models\n",
    "DATA_DIR='/data0/transfer_models/data/'\n",
    "\n",
    "# The gh cli command for listing releases, this shouldn't need to be modified.\n",
    "RELEASE_CMD='gh release list -R https://github.com/educational-technology-collective/transfer_models'\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# read or create history file as needed\n",
    "try:\n",
    "    history=pd.read_csv(f\"{RELEASE_DIR}history.csv\")\n",
    "except:\n",
    "    history=pd.DataFrame(columns=['desc','branch','tag','time'])\n",
    "    history.to_csv(f\"{RELEASE_DIR}history.csv\",index=False)\n",
    "\n",
    "# query for a list of available releases\n",
    "releases=!$RELEASE_CMD\n",
    "releases=pd.read_csv(io.StringIO(\"\\n\".join(releases)), sep='\\t', names=['desc','branch','tag','time'])\n",
    "\n",
    "# iterate through releases to begin processing them\n",
    "for idx,row in releases.iterrows():\n",
    "    tag=row[\"tag\"]\n",
    "    if len(history.query(f'tag==@tag'))==0:\n",
    "        #download this new release\n",
    "        MKDIR_CMD=f\"mkdir {RELEASE_DIR}{tag}\"\n",
    "        DOWNLOAD_CMD=f\"gh api https://api.github.com/repos/educational-technology-collective/transfer_models/tarball/{tag} | tar -zxf - -C {RELEASE_DIR}{tag}\"\n",
    "        !$MKDIR_CMD\n",
    "        !$DOWNLOAD_CMD\n",
    "        \n",
    "        # determine where the project has unarchived to\n",
    "        ROOT_CMD= f\"ls {RELEASE_DIR}{tag}/\"\n",
    "        PROJECT_ROOT=!$ROOT_CMD \n",
    "        PROJECT_ROOT=f\"{RELEASE_DIR}{tag}/{PROJECT_ROOT[0]}\"\n",
    "        \n",
    "        # sync preprocessed datafiles\n",
    "        !cp -R $DATA_DIR $PROJECT_ROOT\n",
    "        \n",
    "        # set directory to the root and begin analysis\n",
    "        %cd $PROJECT_ROOT\n",
    "        !/data1/home/brooksch/.conda/envs/python3.8transfer/bin/python scripts/train_dummy_model.py --src_institution um \n",
    "        \n",
    "        # push files up to shared repository (drive)\n",
    "        !rclone mkdir transfer:/$tag\n",
    "        METRICS=PROJECT_ROOT+\"/metrics\"\n",
    "        MODELS=PROJECT_ROOT+\"/models\"\n",
    "        !rclone copy $METRICS transfer:/$tag/\n",
    "        !rclone copy $MODELS transfer:/$tag/\n",
    "        \n",
    "        # check if all files in drive, if so evaluate\n",
    "        \n",
    "        # record that this has run\n",
    "        history=history.append(row)\n",
    "        # save to file in case subsequent runs cause problems, e.g. multiple releases and the first fails\n",
    "        history.to_csv(f\"{RELEASE_DIR}history.csv\",index=False)\n",
    "        \n",
    "        # restore location to script root\n",
    "        %cd -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8transfer",
   "language": "python",
   "name": "python3.8transfer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
