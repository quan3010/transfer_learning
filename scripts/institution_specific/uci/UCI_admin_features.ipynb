{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Admin features for UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "from scipy.stats import zscore, mode\n",
    "from itertools import product\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DB\n",
    "with open('G:/My Drive/RY_UCI/Research/LMS/uci_connect_string.txt', mode='r') as f:\n",
    "    conn_str = f.read()\n",
    "engine = create_engine(conn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('G:/My Drive/RY_UCI/Research/Mellon/Admin data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codes for term name conversion\n",
    "qtr_codes = {'03':'Winter', '14':'Spring', '51':'Summer', '92':'Fall'}\n",
    "qtr_mos = {'Fall': 10, 'Winter': 1, 'Spring': 4, 'Summer': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letter grade to grade point\n",
    "letter_gp = {'A+': 4, 'A': 4, 'A-': 3.7, 'B+': 3.3, 'B': 3,\n",
    "            'B-': 2.7, 'C+': 2.3, 'C': 2, 'C-': 1.7, 'D+': 1.3,\n",
    "            'D': 1, 'D-': 0.7, 'F': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "COURSE_TYPES = [\"LEC\", \"DIS\", \"SEM\", \"LAB\", \"others\", \"MISSING\"]\n",
    "# COURSE_COMBINED_TYPES contains the following:\n",
    "COURSE_COMBINED_TYPES = [\n",
    "    \"-\".join(c) for c in\n",
    "    product(COURSE_TYPES, COURSE_TYPES)\n",
    "    if c[0] < c[1]]\n",
    "# MODALITIES = [\"online\", \"inperson\", \"MISSING\"]\n",
    "CIP2_CATEGORIES = [\"{:02}\".format(i) for i in range(1, 62)] + [\"MISSING\", ]\n",
    "COURSE_TYPES_COLS = 'units_type_' + pd.Index(COURSE_TYPES+COURSE_COMBINED_TYPES)\n",
    "# MODALITIES_COLS = 'units_modality_' + pd.Index(MODALITIES)\n",
    "CIP2_CATEGORIES_COLS = 'units_cip2_' + pd.Index(CIP2_CATEGORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch student-level table from DB (with selected variables)\n",
    "student_query = \"SELECT mellon_id, birth_year, birth_month, gender, ethnicity, urm, citizenship_app, application_term_code, hs_gpa, sat_math_score, sat_verb_score, act_english_score, act_math_score FROM PRES.vw_student;\"\n",
    "st = pd.read_sql(student_query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Read student-level table from local machine (with selected variables)\n",
    "st = pd.read_csv(data_dir/'cleaned_student_background_data(20211222).csv',\n",
    "                 usecols = ['mellon_id', 'birth_year', 'birth_month', 'gender', 'ethnicity', 'urm', 'citizenship_app', 'application_term_code', 'hs_gpa', 'sat_math_score', 'sat_verb_score', 'act_english_score', 'act_math_score'],\n",
    "                 encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode variables for consistency\n",
    "st['sex'] = st['gender'].map({'F': 'Female', 'M': 'Male', 'X': 'Other', 'U': 'NotIndicated'}).fillna('NotIndicated')\n",
    "st['ethnicity'] = st['ethnicity'].map({\n",
    "    'White non-Hispanic': 'White',\n",
    "    'Asian / Asian American': 'Asian',\n",
    "    'Hispanic': 'Hispanic',\n",
    "    'Black': 'Black',\n",
    "    'American Indian / Alaskan Native': 'Native Amr',\n",
    "    'Pacific Islander': 'Hawaiian',\n",
    "    'Two or more ethnicities':'2 or More',\n",
    "    'Unknown / declined to state': 'Not Indic',\n",
    "    'Unknown': 'Not Indic'    \n",
    "}).fillna('Not Indic')\n",
    "st['urm_status'] = np.where(\n",
    "    st['citizenship_app'] == 'Not US Citizen',\n",
    "    'International',\n",
    "    np.where(\n",
    "        st['urm'] == 1, \n",
    "        'Underrepresented Minority',\n",
    "        'Non-Underrepresented Minority'\n",
    "    )\n",
    ")\n",
    "st['hs_gpa'] = st['hs_gpa'].clip(0,5)\n",
    "# st['modality'] = 'inperson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename variables for consistency\n",
    "st = st.rename(columns={\n",
    "    'hs_gpa': 'gpa_high_school',\n",
    "    'sat_math_score': 'sat_math',\n",
    "    'sat_verb_score': 'sat_verbal',\n",
    "    'act_english_score': 'act_english',\n",
    "    'act_math_score': 'act_math'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 134146 entries, 0 to 134145\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   mellon_id              134146 non-null  int64  \n",
      " 1   birth_year             134082 non-null  float64\n",
      " 2   birth_month            134101 non-null  float64\n",
      " 3   gender                 133654 non-null  object \n",
      " 4   ethnicity              134146 non-null  object \n",
      " 5   urm                    114265 non-null  float64\n",
      " 6   citizenship_app        62745 non-null   object \n",
      " 7   application_term_code  129865 non-null  float64\n",
      " 8   gpa_high_school        90247 non-null   float64\n",
      " 9   sat_math               64484 non-null   float64\n",
      " 10  sat_verbal             35473 non-null   float64\n",
      " 11  act_english            27815 non-null   float64\n",
      " 12  act_math               27815 non-null   float64\n",
      " 13  sex                    134146 non-null  object \n",
      " 14  urm_status             134146 non-null  object \n",
      "dtypes: float64(9), int64(1), object(5)\n",
      "memory usage: 15.4+ MB\n"
     ]
    }
   ],
   "source": [
    "st.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student-term features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch student-term-level table from DB (with selected variables)\n",
    "student_term_query = \"SELECT mellon_id, term_code, current_units_completed_transfer, current_units_completed_total, gpa_cumulative, major_cip_code_1, major_cip_code_2 FROM PRES.vw_student_term;\"\n",
    "sttm = pd.read_sql(student_term_query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read student-term-level table from local machine (with selected variables)\n",
    "sttm = pd.read_csv(data_dir/'cleaned_student_term_data(20211222).csv',\n",
    "                   usecols = ['mellon_id', 'term_code', 'current_units_completed_transfer', 'current_units_completed_total', 'gpa_cumulative', 'major_cip_code_1', 'major_cip_code_2'],\n",
    "                   encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify data types\n",
    "sttm['term_code'] = sttm['term_code'].astype(int)\n",
    "sttm[['current_units_completed_transfer', 'current_units_completed_total']] = sttm[['current_units_completed_transfer', 'current_units_completed_total']].astype(float)\n",
    "sttm[['major_cip_code_1', 'major_cip_code_2']] = sttm[['major_cip_code_1', 'major_cip_code_2']].replace({'&': np.nan}).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge students' birth info and compute age in each term\n",
    "sttm = sttm.merge(st[['mellon_id', 'birth_year', 'birth_month']], on='mellon_id', how='left')\n",
    "sttm['year'] = np.where(sttm['term_code'].notnull(), sttm['term_code'].astype(str).str[:4].astype(int), np.nan)\n",
    "# sttm['term_start_date'] = pd.to_datetime(sttm['term_code'].apply(lambda x: f'{x[:4]}-{qtr_mos[qtr_codes[x[-2:]]]}-1' if x.isdigit() else np.nan), errors = 'coerce')\n",
    "# sttm['birth_date'] = pd.to_datetime(sttm['birth_year'] +'-' + sttm['birth_month'] + '-1', errors = 'coerce')\n",
    "# sttm['age'] = (sttm['term_start_date'] - sttm['birth_date']) / np.timedelta64(1, 'Y')\n",
    "sttm['age'] = sttm['year'].subtract(sttm['birth_year'].astype(float).astype('Int64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode variables for consistency\n",
    "for i in np.arange(2)+1:\n",
    "    sttm[f'cip2_major_{i}'] = sttm[f'major_cip_code_{i}'].apply(lambda x: '{:02}'.format(math.floor(x)) if pd.notnull(x) else 'MISSING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_fall(term_code):\n",
    "    if pd.isnull(term_code):\n",
    "        return None\n",
    "    elif term_code % 100 == 92:\n",
    "        return (term_code + 100)\n",
    "    else:\n",
    "        return (100 * math.floor(term_code / 100) + 92)\n",
    "\n",
    "def get_retention_list(term_codes):\n",
    "    term_code_list = [int(term) for term in term_codes if pd.notnull(term)]\n",
    "    return [get_next_fall(term) in term_code_list for term in term_codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute retention flag: whether a given student in a given term enrolled in the following Fall\n",
    "sttm['retention'] = sttm.groupby('mellon_id')['term_code'].transform(get_retention_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename variables for consistency\n",
    "sttm = sttm.rename(columns={\n",
    "    'current_units_completed_total': 'units',\n",
    "    'current_units_completed_transfer': 'units_transferred',\n",
    "    'gpa_term': 'gpa_avg'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1105422 entries, 0 to 1105421\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   mellon_id          1105422 non-null  int64  \n",
      " 1   term_code          1105422 non-null  int32  \n",
      " 2   units_transferred  1105422 non-null  float64\n",
      " 3   units              1105422 non-null  float64\n",
      " 4   gpa_cumulative     1105422 non-null  float64\n",
      " 5   major_cip_code_1   775597 non-null   float64\n",
      " 6   major_cip_code_2   0 non-null        float64\n",
      " 7   birth_year         832685 non-null   float64\n",
      " 8   birth_month        832686 non-null   float64\n",
      " 9   year               1105422 non-null  float64\n",
      " 10  age                832685 non-null   Float64\n",
      " 11  cip2_major_1       1105422 non-null  object \n",
      " 12  cip2_major_2       1105422 non-null  object \n",
      " 13  retention          1105422 non-null  bool   \n",
      "dtypes: Float64(1), bool(1), float64(8), int32(1), int64(1), object(2)\n",
      "memory usage: 116.0+ MB\n"
     ]
    }
   ],
   "source": [
    "sttm.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student-term-course features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightstats(x, weights=None, stat='mean'):\n",
    "    '''\n",
    "    Extended stats function that accommodates missing values and sample weights\n",
    "    \n",
    "    '''\n",
    "    x = np.asarray(x)\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(x))\n",
    "    else:\n",
    "        weights = np.asarray(weights).astype(float)\n",
    "    indices = ((~np.isnan(x)) & (~np.isnan(weights)))\n",
    "    if ~indices.any():\n",
    "        return np.nan\n",
    "    else:\n",
    "        x = x[indices]\n",
    "        weights = weights[indices]\n",
    "        mean = np.dot(x.T, weights) / weights.sum()\n",
    "        if stat == 'mean':\n",
    "            return mean\n",
    "        std = np.sqrt(np.dot(((x - mean) ** 2).T, weights) / weights.sum())\n",
    "        if stat == 'std':\n",
    "            return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_stcs(chunk):\n",
    "    '''\n",
    "    For a given chunk of student-course-level table, derive the aggregated student-term table\n",
    "    \n",
    "    '''\n",
    "    # ID headers\n",
    "    chunk_agg = chunk[['mellon_id', 'term_code']].drop_duplicates()\n",
    "    print('ID headers done.')\n",
    "    \n",
    "    # Units by course type\n",
    "    chunk['course_type'] = chunk['course_type'].fillna('MISSING').replace({'': 'MISSING'})\n",
    "    chunk['course_type_rec'] = chunk['course_type'].where(\n",
    "        chunk['course_type'].isin(['LEC', 'DIS', 'SEM', 'LAB', 'MISSING']),\n",
    "        'others'\n",
    "    )\n",
    "    chunk['course_type_concat'] = chunk.groupby(['mellon_id', 'term_code', 'course_dept_code_and_num'], as_index=False)['course_type_rec'].transform(lambda x: x.sort_values().drop_duplicates().str.cat(sep='-')).replace({'': None})\n",
    "    units_by_course_type = pd.pivot_table(chunk.groupby(['mellon_id', 'term_code', 'course_type_concat'], as_index=False)['units_completed'].sum(),\n",
    "                                          index=['mellon_id', 'term_code'], columns='course_type_concat', values='units_completed',\n",
    "                                          aggfunc='sum').add_prefix('units_type_')\n",
    "    units_by_course_type = units_by_course_type.drop(columns=units_by_course_type.columns.difference(COURSE_TYPES_COLS))\n",
    "    units_by_course_type[COURSE_TYPES_COLS.difference(units_by_course_type.columns)] = np.nan\n",
    "    chunk_agg = chunk_agg.merge(units_by_course_type.reset_index(), how='left', on=['mellon_id', 'term_code'])\n",
    "    print('Units by course type done.')\n",
    "    \n",
    "    # Units by course modality\n",
    "#     chunk['meeting_location'] = chunk['meeting_location'].str.strip().str.upper().str.replace(r'(\\t|\\n|\\s)+', '').replace({'': None})\n",
    "#     chunk['format'] = np.where(\n",
    "#         chunk['meeting_location'].str.contains('TBA') | chunk['meeting_location'].isnull(),\n",
    "#         'MISSING',\n",
    "#         np.where(\n",
    "#             chunk['meeting_location'].str.contains(r'(ONLINE)|(REMOTE)'),\n",
    "#             'online',\n",
    "#             'inperson'\n",
    "#         )\n",
    "#     )\n",
    "#     units_by_modality = pd.pivot_table(chunk.groupby(['mellon_id', 'term_code', 'format'], as_index=False)['units_completed'].sum(),\n",
    "#                                        index=['mellon_id', 'term_code'], columns='format', values='units_completed',\n",
    "#                                        aggfunc='sum').add_prefix('units_modality_')\n",
    "#     units_by_modality = units_by_modality.drop(columns=units_by_modality.columns.difference(MODALITIES_COLS))\n",
    "#     units_by_modality[MODALITIES_COLS.difference(units_by_modality.columns)] = np.nan\n",
    "#     chunk_agg = chunk_agg.merge(units_by_modality.reset_index(), how='left', on=['mellon_id', 'term_code'])\n",
    "#     print('Units by course modality done.')\n",
    "    \n",
    "    # Units by cip codes\n",
    "    chunk['course_cip2'] = chunk.groupby(['term_code', 'course_code'])['cip2_major_1'].transform(lambda x: pd.Series.mode(x)[0] if len(pd.Series.mode(x)) > 0 else None).fillna('MISSING')\n",
    "    units_by_cip2 = pd.pivot_table(chunk.groupby(['mellon_id', 'term_code', 'course_cip2'], as_index=False)['units_completed'].sum(),\n",
    "                                   index=['mellon_id', 'term_code'], columns='course_cip2', values='units_completed',\n",
    "                                   aggfunc='sum').add_prefix('units_cip2_')\n",
    "    units_by_cip2 = units_by_cip2.drop(columns=units_by_cip2.columns.difference(CIP2_CATEGORIES_COLS))\n",
    "    units_by_cip2[CIP2_CATEGORIES_COLS.difference(units_by_cip2.columns)] = np.nan   \n",
    "    chunk_agg = chunk_agg.merge(units_by_cip2.reset_index(), how='left', on=['mellon_id', 'term_code'])\n",
    "    print('Units by CIP codes done.')\n",
    "    \n",
    "    # Failed/incompleted/withdrawn units\n",
    "    chunk_agg = chunk_agg.merge(\n",
    "        chunk[chunk['final_grade']=='F'].groupby(['mellon_id', 'term_code'], as_index=False)['units_completed'].sum().rename(columns={'units_completed': 'units_failed'}),\n",
    "        how='left', on=['mellon_id', 'term_code']\n",
    "    )\n",
    "    chunk_agg = chunk_agg.merge(\n",
    "        chunk[chunk['final_grade']=='I'].groupby(['mellon_id', 'term_code'], as_index=False)['units_completed'].sum().rename(columns={'units_completed': 'units_incompleted'}),\n",
    "        how='left', on=['mellon_id', 'term_code']\n",
    "    )\n",
    "    chunk_agg = chunk_agg.merge(\n",
    "        chunk[chunk['final_grade']=='W'].groupby(['mellon_id', 'term_code'], as_index=False)['units_completed'].sum().rename(columns={'units_completed': 'units_withdrawn'}),\n",
    "        how='left', on=['mellon_id', 'term_code']\n",
    "    )\n",
    "    print('Failed/incompleted/withdrawn units done.')\n",
    "    \n",
    "    # Fill 0s for all missing values so far\n",
    "    chunk_agg = chunk_agg.fillna(0)\n",
    "    \n",
    "    # GPA stats\n",
    "    chunk['grade_point'] = chunk['final_grade'].map(letter_gp)\n",
    "    chunk['grade_point_z'] = chunk.groupby(['term_code', 'course_code'])['grade_point'].transform(zscore, nan_policy='omit')\n",
    "    chunk_agg = chunk_agg.merge(\n",
    "        chunk.groupby(['mellon_id', 'term_code']).apply(lambda x: weightstats(x['grade_point'], weights=x['units_completed'], stat='mean')).reset_index(name='gpa_avg'),\n",
    "        how='left', on=['mellon_id', 'term_code']\n",
    "    )\n",
    "    chunk_agg = chunk_agg.merge(\n",
    "        chunk.groupby(['mellon_id', 'term_code']).apply(lambda x: weightstats(x['grade_point'], weights=x['units_completed'], stat='std')).reset_index(name='gpa_stddev'),\n",
    "        how='left', on=['mellon_id', 'term_code']\n",
    "    )\n",
    "    chunk_agg = chunk_agg.merge(\n",
    "        chunk.groupby(['mellon_id', 'term_code']).apply(lambda x: weightstats(x['grade_point_z'], weights=x['units_completed'], stat='mean')).reset_index(name='gpa_zscore_avg'),\n",
    "        how='left', on=['mellon_id', 'term_code']\n",
    "    )\n",
    "    chunk_agg = chunk_agg.merge(\n",
    "        chunk.groupby(['mellon_id', 'term_code']).apply(lambda x: weightstats(x['grade_point_z'], weights=x['units_completed'], stat='std')).reset_index(name='gpa_zscore_stddev'),\n",
    "        how='left', on=['mellon_id', 'term_code']\n",
    "    )\n",
    "    print('GPA stats done.')\n",
    "    \n",
    "    return chunk_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [201292, 201392, 201492, 201592, 201692, 201792, 201892, 201992]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch student-term-course-level table from DB (with selected variables), one term at a time\n",
    "student_course_query = '''\n",
    "SELECT mellon_id, term_code, course_code, course_dept_code_and_num, course_section_num, course_type, meeting_location, units_attempted, units_completed, final_grade \n",
    "FROM PRES.vw_stcs\n",
    "WHERE term_code = %s;\n",
    "'''\n",
    "# Loop through all terms, and concatenate the aggregated table from each term\n",
    "for term in terms:    \n",
    "    chunk = pd.read_sql(student_course_query, engine, params=(term,))\n",
    "    chunk = chunk.merge(sttm[['mellon_id', 'term_code', 'cip2_major_1']], how='left')\n",
    "    chunk_agg = agg_stcs(chunk)\n",
    "    try:\n",
    "        stcs_agg = stcs_agg.append(chunk_agg)\n",
    "    except:\n",
    "        stcs_agg = chunk_agg\n",
    "    print(f'Term {term} finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read student-term-course-level table from local machine (with selected variables)\n",
    "itr = pd.read_csv(data_dir/'cleaned_student_term_course_section(20211222).csv',\n",
    "                  usecols = ['mellon_id', 'term_code', 'course_code', 'course_dept_code_and_num', 'course_section_num', 'course_type', 'meeting_location', 'units_attempted', 'units_completed', 'final_grade'],\n",
    "                  encoding='ISO-8859-1', iterator=True, chunksize=1000000)\n",
    "for chunk in itr:\n",
    "    try:\n",
    "        stcs = stcs.append(chunk[chunk['term_code'].isin(terms)])\n",
    "    except:\n",
    "        stcs = chunk[chunk['term_code'].isin(terms)]\n",
    "stcs = stcs.merge(sttm[['mellon_id', 'term_code', 'cip2_major_1']], how='left')\n",
    "stcs['cip2_major_1'] = stcs['cip2_major_1'].fillna('MISSING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID headers done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuren\\AppData\\Local\\Temp/ipykernel_21224/287612154.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['course_type'] = chunk['course_type'].fillna('MISSING').replace({'': 'MISSING'})\n",
      "C:\\Users\\yuren\\AppData\\Local\\Temp/ipykernel_21224/287612154.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['course_type_rec'] = chunk['course_type'].where(\n",
      "C:\\Users\\yuren\\AppData\\Local\\Temp/ipykernel_21224/287612154.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['course_type_concat'] = chunk.groupby(['mellon_id', 'term_code', 'course_dept_code_and_num'], as_index=False)['course_type_rec'].transform(lambda x: x.sort_values().drop_duplicates().str.cat(sep='-')).replace({'': None})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Units by course type done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuren\\AppData\\Local\\Temp/ipykernel_21224/287612154.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['course_cip2'] = chunk.groupby(['term_code', 'course_code'])['cip2_major_1'].transform(lambda x: pd.Series.mode(x)[0] if len(pd.Series.mode(x)) > 0 else None).fillna('MISSING')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Units by CIP codes done.\n",
      "Failed/incompleted/withdrawn units done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuren\\AppData\\Local\\Temp/ipykernel_21224/287612154.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['grade_point'] = chunk['final_grade'].map(letter_gp)\n",
      "C:\\Users\\yuren\\AppData\\Local\\Temp/ipykernel_21224/287612154.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['grade_point_z'] = chunk.groupby(['term_code', 'course_code'])['grade_point'].transform(zscore, nan_policy='omit')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPA stats done.\n",
      "Term 201292 finished.\n",
      "ID headers done.\n",
      "Units by course type done.\n",
      "Units by CIP codes done.\n",
      "Failed/incompleted/withdrawn units done.\n",
      "GPA stats done.\n",
      "Term 201392 finished.\n",
      "ID headers done.\n",
      "Units by course type done.\n",
      "Units by CIP codes done.\n",
      "Failed/incompleted/withdrawn units done.\n",
      "GPA stats done.\n",
      "Term 201492 finished.\n",
      "ID headers done.\n",
      "Units by course type done.\n",
      "Units by CIP codes done.\n",
      "Failed/incompleted/withdrawn units done.\n",
      "GPA stats done.\n",
      "Term 201592 finished.\n",
      "ID headers done.\n",
      "Units by course type done.\n",
      "Units by CIP codes done.\n",
      "Failed/incompleted/withdrawn units done.\n",
      "GPA stats done.\n",
      "Term 201692 finished.\n",
      "ID headers done.\n",
      "Units by course type done.\n",
      "Units by CIP codes done.\n",
      "Failed/incompleted/withdrawn units done.\n",
      "GPA stats done.\n",
      "Term 201792 finished.\n",
      "ID headers done.\n",
      "Units by course type done.\n",
      "Units by CIP codes done.\n",
      "Failed/incompleted/withdrawn units done.\n",
      "GPA stats done.\n",
      "Term 201892 finished.\n",
      "ID headers done.\n",
      "Units by course type done.\n",
      "Units by CIP codes done.\n",
      "Failed/incompleted/withdrawn units done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuren\\AppData\\Local\\Temp/ipykernel_21224/3477483650.py:17: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mean = np.dot(x.T, weights) / weights.sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPA stats done.\n",
      "Term 201992 finished.\n"
     ]
    }
   ],
   "source": [
    "for term in terms:\n",
    "    chunk_agg = agg_stcs(stcs[stcs['term_code']==term])\n",
    "    try:\n",
    "        stcs_agg = stcs_agg.append(chunk_agg)\n",
    "    except:\n",
    "        stcs_agg = chunk_agg\n",
    "    print(f'Term {term} finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 218917 entries, 0 to 36463\n",
      "Data columns (total 92 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   mellon_id                  218917 non-null  int64  \n",
      " 1   term_code                  218917 non-null  int64  \n",
      " 2   units_type_DIS             218917 non-null  float64\n",
      " 3   units_type_DIS-LAB         218917 non-null  float64\n",
      " 4   units_type_DIS-LEC         218917 non-null  float64\n",
      " 5   units_type_DIS-MISSING     218917 non-null  float64\n",
      " 6   units_type_DIS-SEM         218917 non-null  float64\n",
      " 7   units_type_DIS-others      218917 non-null  float64\n",
      " 8   units_type_LAB             218917 non-null  float64\n",
      " 9   units_type_LAB-LEC         218917 non-null  float64\n",
      " 10  units_type_LAB-MISSING     218917 non-null  float64\n",
      " 11  units_type_LEC             218917 non-null  float64\n",
      " 12  units_type_LEC-MISSING     218917 non-null  float64\n",
      " 13  units_type_LEC-others      218917 non-null  float64\n",
      " 14  units_type_MISSING         218917 non-null  float64\n",
      " 15  units_type_MISSING-SEM     218917 non-null  float64\n",
      " 16  units_type_MISSING-others  218917 non-null  float64\n",
      " 17  units_type_SEM             218917 non-null  float64\n",
      " 18  units_type_SEM-others      218917 non-null  float64\n",
      " 19  units_type_others          218917 non-null  float64\n",
      " 20  units_type_LAB-SEM         218917 non-null  float64\n",
      " 21  units_type_LAB-others      218917 non-null  float64\n",
      " 22  units_type_LEC-SEM         218917 non-null  float64\n",
      " 23  units_cip2_05              218917 non-null  float64\n",
      " 24  units_cip2_09              218917 non-null  float64\n",
      " 25  units_cip2_11              218917 non-null  float64\n",
      " 26  units_cip2_14              218917 non-null  float64\n",
      " 27  units_cip2_16              218917 non-null  float64\n",
      " 28  units_cip2_23              218917 non-null  float64\n",
      " 29  units_cip2_26              218917 non-null  float64\n",
      " 30  units_cip2_27              218917 non-null  float64\n",
      " 31  units_cip2_30              218917 non-null  float64\n",
      " 32  units_cip2_38              218917 non-null  float64\n",
      " 33  units_cip2_40              218917 non-null  float64\n",
      " 34  units_cip2_42              218917 non-null  float64\n",
      " 35  units_cip2_45              218917 non-null  float64\n",
      " 36  units_cip2_50              218917 non-null  float64\n",
      " 37  units_cip2_51              218917 non-null  float64\n",
      " 38  units_cip2_52              218917 non-null  float64\n",
      " 39  units_cip2_54              218917 non-null  float64\n",
      " 40  units_cip2_MISSING         218917 non-null  float64\n",
      " 41  units_cip2_01              218917 non-null  float64\n",
      " 42  units_cip2_02              218917 non-null  float64\n",
      " 43  units_cip2_03              218917 non-null  float64\n",
      " 44  units_cip2_04              218917 non-null  float64\n",
      " 45  units_cip2_06              218917 non-null  float64\n",
      " 46  units_cip2_07              218917 non-null  float64\n",
      " 47  units_cip2_08              218917 non-null  float64\n",
      " 48  units_cip2_10              218917 non-null  float64\n",
      " 49  units_cip2_12              218917 non-null  float64\n",
      " 50  units_cip2_13              218917 non-null  float64\n",
      " 51  units_cip2_15              218917 non-null  float64\n",
      " 52  units_cip2_17              218917 non-null  float64\n",
      " 53  units_cip2_18              218917 non-null  float64\n",
      " 54  units_cip2_19              218917 non-null  float64\n",
      " 55  units_cip2_20              218917 non-null  float64\n",
      " 56  units_cip2_21              218917 non-null  float64\n",
      " 57  units_cip2_22              218917 non-null  float64\n",
      " 58  units_cip2_24              218917 non-null  float64\n",
      " 59  units_cip2_25              218917 non-null  float64\n",
      " 60  units_cip2_28              218917 non-null  float64\n",
      " 61  units_cip2_29              218917 non-null  float64\n",
      " 62  units_cip2_31              218917 non-null  float64\n",
      " 63  units_cip2_32              218917 non-null  float64\n",
      " 64  units_cip2_33              218917 non-null  float64\n",
      " 65  units_cip2_34              218917 non-null  float64\n",
      " 66  units_cip2_35              218917 non-null  float64\n",
      " 67  units_cip2_36              218917 non-null  float64\n",
      " 68  units_cip2_37              218917 non-null  float64\n",
      " 69  units_cip2_39              218917 non-null  float64\n",
      " 70  units_cip2_41              218917 non-null  float64\n",
      " 71  units_cip2_43              218917 non-null  float64\n",
      " 72  units_cip2_44              218917 non-null  float64\n",
      " 73  units_cip2_46              218917 non-null  float64\n",
      " 74  units_cip2_47              218917 non-null  float64\n",
      " 75  units_cip2_48              218917 non-null  float64\n",
      " 76  units_cip2_49              218917 non-null  float64\n",
      " 77  units_cip2_53              218917 non-null  float64\n",
      " 78  units_cip2_55              218917 non-null  float64\n",
      " 79  units_cip2_56              218917 non-null  float64\n",
      " 80  units_cip2_57              218917 non-null  float64\n",
      " 81  units_cip2_58              218917 non-null  float64\n",
      " 82  units_cip2_59              218917 non-null  float64\n",
      " 83  units_cip2_60              218917 non-null  float64\n",
      " 84  units_cip2_61              218917 non-null  float64\n",
      " 85  units_failed               218917 non-null  float64\n",
      " 86  units_incompleted          218917 non-null  float64\n",
      " 87  units_withdrawn            218917 non-null  float64\n",
      " 88  gpa_avg                    211031 non-null  float64\n",
      " 89  gpa_stddev                 211031 non-null  float64\n",
      " 90  gpa_zscore_avg             209607 non-null  float64\n",
      " 91  gpa_zscore_stddev          209607 non-null  float64\n",
      "dtypes: float64(90), int64(2)\n",
      "memory usage: 155.3 MB\n"
     ]
    }
   ],
   "source": [
    "stcs_agg.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = stcs_agg.merge(sttm.drop(columns=['birth_year', 'birth_month', 'major_cip_code_1', 'major_cip_code_2']), how='inner', on=['mellon_id', 'term_code'])\n",
    "combined = combined.merge(st.drop(columns=['birth_year', 'birth_month', 'gender', 'citizenship_app', 'urm']), how='inner', on=['mellon_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined[combined['application_term_code'] == combined['term_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.drop(columns=['mellon_id', 'term_code', 'application_term_code']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64892 entries, 0 to 64891\n",
      "Columns: 106 entries, units_type_DIS to urm_status\n",
      "dtypes: Float64(1), bool(1), float64(99), object(5)\n",
      "memory usage: 52.1+ MB\n"
     ]
    }
   ],
   "source": [
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_feather('G:/My Drive/RY_UCI/Research/Transfer Models/transfer_models/data/preprocessed/uci.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
